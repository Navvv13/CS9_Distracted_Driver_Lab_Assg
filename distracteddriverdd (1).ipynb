{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-16T16:21:21.118301Z","iopub.execute_input":"2022-03-16T16:21:21.118929Z","iopub.status.idle":"2022-03-16T16:22:22.309570Z","shell.execute_reply.started":"2022-03-16T16:21:21.118887Z","shell.execute_reply":"2022-03-16T16:22:22.308786Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"IMPORTING ALL THE RELEVANT LIBRARIES\n* MADE USE OF KERAS PROMINENTLY","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport pickle \nimport shutil \nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.311476Z","iopub.execute_input":"2022-03-16T16:22:22.311781Z","iopub.status.idle":"2022-03-16T16:22:22.317143Z","shell.execute_reply.started":"2022-03-16T16:22:22.311738Z","shell.execute_reply":"2022-03-16T16:22:22.316337Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"In the above mentioned code we have used PICKLE AND SHUTIL which i have described below:\n1. PICKLE - serializing and deserializing a Python object structure - coverting it into a byte stream - process called pickling\n2.  SHUTIL - provides many functions of high-level operations on files and collections of files","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_files\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.318572Z","iopub.execute_input":"2022-03-16T16:22:22.319026Z","iopub.status.idle":"2022-03-16T16:22:22.328104Z","shell.execute_reply.started":"2022-03-16T16:22:22.318981Z","shell.execute_reply":"2022-03-16T16:22:22.327312Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"from keras.utils import np_utils\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.330358Z","iopub.execute_input":"2022-03-16T16:22:22.330831Z","iopub.status.idle":"2022-03-16T16:22:22.338844Z","shell.execute_reply.started":"2022-03-16T16:22:22.330792Z","shell.execute_reply":"2022-03-16T16:22:22.337941Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.applications.vgg16 import VGG16\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.340282Z","iopub.execute_input":"2022-03-16T16:22:22.340776Z","iopub.status.idle":"2022-03-16T16:22:22.351140Z","shell.execute_reply.started":"2022-03-16T16:22:22.340737Z","shell.execute_reply":"2022-03-16T16:22:22.350364Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.352749Z","iopub.execute_input":"2022-03-16T16:22:22.353062Z","iopub.status.idle":"2022-03-16T16:22:22.360212Z","shell.execute_reply.started":"2022-03-16T16:22:22.353022Z","shell.execute_reply":"2022-03-16T16:22:22.359258Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"PYTHON IMAGING LIBRARY - PIL, IT ADDS IMAGE PROCESSING TO PYTHON","metadata":{}},{"cell_type":"code","source":"\nfrom PIL import ImageFile \nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.362008Z","iopub.execute_input":"2022-03-16T16:22:22.362219Z","iopub.status.idle":"2022-03-16T16:22:22.369565Z","shell.execute_reply.started":"2022-03-16T16:22:22.362193Z","shell.execute_reply":"2022-03-16T16:22:22.368597Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"\n\nBelow we have used the OS MODULE - it helps in connecting/interacting  with the operating system.\nos.path.join() that we have used below is a method in Python  which is used to join one or more path components intelligently.\n\n\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"datalink = \"../input/state-farm-distracted-driver-detection/imgs\"\ntest_data = os.path.join(datalink,\"test\")\ntrain_data = os.path.join(datalink,\"train\")","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.371254Z","iopub.execute_input":"2022-03-16T16:22:22.371576Z","iopub.status.idle":"2022-03-16T16:22:22.379366Z","shell.execute_reply.started":"2022-03-16T16:22:22.371514Z","shell.execute_reply":"2022-03-16T16:22:22.378218Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"csvlink = os.path.join(os.getcwd(),\"csv_files\")\nmodelpath = os.path.join(os.getcwd(),\"model\",\"vgg16\")\npicklepath = os.path.join(os.getcwd(),\"pickle\")\ntestcsv = os.path.join(os.getcwd(),\"csv_files\",\"test.csv\")\ntraincsv = os.path.join(os.getcwd(),\"csv_files\",\"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.381284Z","iopub.execute_input":"2022-03-16T16:22:22.381618Z","iopub.status.idle":"2022-03-16T16:22:22.390133Z","shell.execute_reply.started":"2022-03-16T16:22:22.381576Z","shell.execute_reply":"2022-03-16T16:22:22.388962Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(test_data):\n    print(\"Testing data -> does not exists\")\nif not os.path.exists(train_data):\n    print(\"Training data -> does not exists\")\nif not os.path.exists(modelpath):\n    print(\"Model path -> does not exists\")\n    os.makedirs(modelpath)\n    print(\"Model path created\")\n    \nelse:\n    shutil.rmtree(modelpath)\n    os.makedirs(modelpath)\nif not os.path.exists(picklepath):\n    os.makedirs(picklepath)\nif not os.path.exists(csvlink):\n    os.makedirs(csvlink)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.394344Z","iopub.execute_input":"2022-03-16T16:22:22.394886Z","iopub.status.idle":"2022-03-16T16:22:22.406523Z","shell.execute_reply.started":"2022-03-16T16:22:22.394847Z","shell.execute_reply":"2022-03-16T16:22:22.405707Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#LENGTH\nprint(len(train_data))\nprint(len(traincsv))\n\nprint(len(test_data))\nprint(len(testcsv))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.408231Z","iopub.execute_input":"2022-03-16T16:22:22.409182Z","iopub.status.idle":"2022-03-16T16:22:22.416112Z","shell.execute_reply.started":"2022-03-16T16:22:22.409140Z","shell.execute_reply":"2022-03-16T16:22:22.415134Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"path. isdir() -> method in Python is used to check whether the specified path is an existing directory or not. If a path has a symbolic link linking to a directory it will return \"TRUE\"","metadata":{}},{"cell_type":"code","source":"def csvfunc(datalink,filename):\n    class_names = os.listdir(datalink)\n    data = list()\n    if(os.path.isdir(os.path.join(datalink,class_names[0]))):\n        for class_name in class_names:\n            file_names = os.listdir(os.path.join(datalink,class_name))\n            for file in file_names:\n                data.append({\n                    \"Filename\":os.path.join(datalink,class_name,file),\n                    \"ClassName\":class_name\n                })\n    else:\n        class_name = \"test\"\n        file_names = os.listdir(datalink)\n        for file in file_names:\n            data.append(({\n                \"FileName\":os.path.join(datalink,file),\n                \"ClassName\":class_name\n            }))\n    data = pd.DataFrame(data)\n    data.to_csv(os.path.join(os.getcwd(),\"csv_files\",filename),index=False)\n\ncsvfunc(train_data,\"train.csv\")\ncsvfunc(test_data,\"test.csv\")\ndata_train = pd.read_csv(os.path.join(os.getcwd(),\"csv_files\",\"train.csv\"))\ndata_test = pd.read_csv(os.path.join(os.getcwd(),\"csv_files\",\"test.csv\"))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:22.417510Z","iopub.execute_input":"2022-03-16T16:22:22.418437Z","iopub.status.idle":"2022-03-16T16:22:23.282985Z","shell.execute_reply.started":"2022-03-16T16:22:22.418398Z","shell.execute_reply":"2022-03-16T16:22:23.282246Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"Details of the images are mentioned below ","metadata":{}},{"cell_type":"code","source":"imgdetails = '../input/state-farm-distracted-driver-detection/'\ndriver_imgs_list = pd.read_csv(os.path.join(imgdetails,'driver_imgs_list.csv'))\ndriver_imgs_list.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:23.284055Z","iopub.execute_input":"2022-03-16T16:22:23.284284Z","iopub.status.idle":"2022-03-16T16:22:23.309661Z","shell.execute_reply.started":"2022-03-16T16:22:23.284253Z","shell.execute_reply":"2022-03-16T16:22:23.308881Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv(traincsv)\ndata_test = pd.read_csv(testcsv)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:23.310972Z","iopub.execute_input":"2022-03-16T16:22:23.311278Z","iopub.status.idle":"2022-03-16T16:22:23.427030Z","shell.execute_reply.started":"2022-03-16T16:22:23.311241Z","shell.execute_reply":"2022-03-16T16:22:23.426289Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#visual representation\ndriver_imgs_list.groupby('classname')['img'].count().sort_values().plot(kind='box')\nplt.ylabel('Images range')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:23.428171Z","iopub.execute_input":"2022-03-16T16:22:23.428409Z","iopub.status.idle":"2022-03-16T16:22:23.591666Z","shell.execute_reply.started":"2022-03-16T16:22:23.428377Z","shell.execute_reply":"2022-03-16T16:22:23.590936Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from keras import *\nfrom keras.utils.np_utils import to_categorical\n\n\nlabels_list = list(set(data_train['ClassName'].values.tolist()))\nlabels_id = {label_name:id for id,label_name in enumerate(labels_list)}\nprint(labels_id)\ndata_train['ClassName'].replace(labels_id,inplace=True)\n\nlabels = to_categorical(data_train['ClassName'])\nprint(labels.shape)\n\nwith open(os.path.join(picklepath,\"labels_list_vgg16.pkl\"),\"wb\") as handle:\n    pickle.dump(labels_id,handle)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:23.593079Z","iopub.execute_input":"2022-03-16T16:22:23.593577Z","iopub.status.idle":"2022-03-16T16:22:23.631244Z","shell.execute_reply.started":"2022-03-16T16:22:23.593529Z","shell.execute_reply":"2022-03-16T16:22:23.630453Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"Below we have printed out the size of each image","metadata":{}},{"cell_type":"code","source":"from PIL import Image \nimg = Image.open('../input/state-farm-distracted-driver-detection/imgs/test/img_1.jpg')\nprint(img.size)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:23.634252Z","iopub.execute_input":"2022-03-16T16:22:23.634453Z","iopub.status.idle":"2022-03-16T16:22:23.639405Z","shell.execute_reply.started":"2022-03-16T16:22:23.634429Z","shell.execute_reply":"2022-03-16T16:22:23.638680Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"* load_img - loads RGB image as PIL.Image type\n* img_to_array - converts tge PIL image type to 3d tensor with a shape.\n*  expand_dims -  convert 3D tensor to 4D tensor with shape (1, 64, 64, 3) and return 4D tensor","metadata":{}},{"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(data_train.iloc[:,0],labels,test_size = 0.2,random_state=42)\ndef path_to_tensor(img_path):\n    \n    img = image.load_img(img_path, target_size=(64, 64))\n    \n    x = image.img_to_array(img)\n\n    return np.expand_dims(x, axis=0)\n\ndef paths_to_tensor(img_paths):\n    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n    return np.vstack(list_of_tensors)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:23.640731Z","iopub.execute_input":"2022-03-16T16:22:23.641615Z","iopub.status.idle":"2022-03-16T16:22:23.657056Z","shell.execute_reply.started":"2022-03-16T16:22:23.641578Z","shell.execute_reply":"2022-03-16T16:22:23.656232Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"Pre-Process the data for Keras","metadata":{}},{"cell_type":"code","source":"ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n\ntrain_tensors = paths_to_tensor(xtrain).astype('float32')/255 - 0.5\nvalid_tensors = paths_to_tensor(xtest).astype('float32')/255 - 0.5","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:22:23.658225Z","iopub.execute_input":"2022-03-16T16:22:23.658523Z","iopub.status.idle":"2022-03-16T16:24:04.069821Z","shell.execute_reply.started":"2022-03-16T16:22:23.658488Z","shell.execute_reply":"2022-03-16T16:24:04.069070Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"model = VGG16(include_top=False)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:24:04.071228Z","iopub.execute_input":"2022-03-16T16:24:04.071492Z","iopub.status.idle":"2022-03-16T16:24:04.341968Z","shell.execute_reply.started":"2022-03-16T16:24:04.071457Z","shell.execute_reply":"2022-03-16T16:24:04.341216Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"model = VGG16(include_top=False)\ntrain_vgg16 = model.predict(train_tensors,verbose=1)\nvalid_vgg16 = model.predict(valid_tensors,verbose=1)\ntrain_features = train_vgg16[0]\nvalid_features = valid_vgg16[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:24:04.343327Z","iopub.execute_input":"2022-03-16T16:24:04.343596Z","iopub.status.idle":"2022-03-16T16:24:13.000458Z","shell.execute_reply.started":"2022-03-16T16:24:04.343560Z","shell.execute_reply":"2022-03-16T16:24:12.999696Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"\n\nVGG16_model = Sequential()\nVGG16_model.add(GlobalAveragePooling2D(input_shape=train_features.shape))\nVGG16_model.add(Dense(10, activation='softmax', kernel_initializer='glorot_normal'))\nVGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:24:13.001947Z","iopub.execute_input":"2022-03-16T16:24:13.002211Z","iopub.status.idle":"2022-03-16T16:24:13.025591Z","shell.execute_reply.started":"2022-03-16T16:24:13.002176Z","shell.execute_reply":"2022-03-16T16:24:13.024916Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"filepath = os.path.join(modelpath,\"distracted-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',period=1)\ncallbacks_list = [checkpoint]","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:24:13.026971Z","iopub.execute_input":"2022-03-16T16:24:13.027219Z","iopub.status.idle":"2022-03-16T16:24:13.035098Z","shell.execute_reply.started":"2022-03-16T16:24:13.027186Z","shell.execute_reply":"2022-03-16T16:24:13.034422Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"model_history = VGG16_model.fit(train_vgg16,ytrain,validation_data = (valid_vgg16, ytest),epochs=200, batch_size=16, shuffle=True,callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:24:13.036346Z","iopub.execute_input":"2022-03-16T16:24:13.036638Z","iopub.status.idle":"2022-03-16T16:34:35.411684Z","shell.execute_reply.started":"2022-03-16T16:24:13.036608Z","shell.execute_reply":"2022-03-16T16:34:35.408650Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(model_history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(model_history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, 400, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(model_history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(model_history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, 400, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:34:35.418261Z","iopub.execute_input":"2022-03-16T16:34:35.418577Z","iopub.status.idle":"2022-03-16T16:34:41.881136Z","shell.execute_reply.started":"2022-03-16T16:34:35.418525Z","shell.execute_reply":"2022-03-16T16:34:41.880435Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    fig.savefig(os.path.join(modelpath,\"confusion_matrix.png\"))\n    return fig","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:34:41.882470Z","iopub.execute_input":"2022-03-16T16:34:41.883238Z","iopub.status.idle":"2022-03-16T16:34:41.892028Z","shell.execute_reply.started":"2022-03-16T16:34:41.883198Z","shell.execute_reply":"2022-03-16T16:34:41.891193Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def print_heatmap(n_labels, n_predictions, class_names):\n    labels = n_labels \n    predictions = n_predictions \n\n    matrix = confusion_matrix(labels.argmax(axis=1),predictions.argmax(axis=1))\n    row_sum = np.sum(matrix, axis = 1)\n    w, h = matrix.shape\n\n    c_m = np.zeros((w, h))\n\n    for i in range(h):\n        c_m[i] = matrix[i] * 100 / row_sum[i]\n\n    c = c_m.astype(dtype = np.uint8)\n\n    \n    heatmap = print_confusion_matrix(c, class_names, figsize=(18,10), fontsize=20)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:34:41.893156Z","iopub.execute_input":"2022-03-16T16:34:41.893476Z","iopub.status.idle":"2022-03-16T16:34:41.902908Z","shell.execute_reply.started":"2022-03-16T16:34:41.893439Z","shell.execute_reply":"2022-03-16T16:34:41.901998Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"class_names = list()\nfor name,idx in labels_id.items():\n    class_names.append(name)\n# print(class_names)\nypred = VGG16_model.predict(valid_vgg16,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:34:41.907182Z","iopub.execute_input":"2022-03-16T16:34:41.907580Z","iopub.status.idle":"2022-03-16T16:34:42.291240Z","shell.execute_reply.started":"2022-03-16T16:34:41.907532Z","shell.execute_reply":"2022-03-16T16:34:42.290461Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"Visual representation using heatmap","metadata":{}},{"cell_type":"code","source":"print_heatmap(ytest,ypred,class_names)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:34:42.294764Z","iopub.execute_input":"2022-03-16T16:34:42.294965Z","iopub.status.idle":"2022-03-16T16:34:43.064745Z","shell.execute_reply.started":"2022-03-16T16:34:42.294940Z","shell.execute_reply":"2022-03-16T16:34:43.064059Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"ypred_class = np.argmax(ypred,axis=1)\nytest = np.argmax(ytest,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:34:43.065842Z","iopub.execute_input":"2022-03-16T16:34:43.066714Z","iopub.status.idle":"2022-03-16T16:34:43.071315Z","shell.execute_reply.started":"2022-03-16T16:34:43.066675Z","shell.execute_reply":"2022-03-16T16:34:43.070656Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"FORMULAS OF PRECISION. RECALL\n* precision tp / (tp + fp)\n* recall: tp / (tp + fn)\n* f1: 2 tp / (2 tp + fp + fn)\n* Accuracy: (tp+tn)/(tp+tn+fp+fn)","metadata":{}},{"cell_type":"code","source":"accuracy = accuracy_score(ytest,ypred_class)\nprint('Accuracy -  %f' % accuracy)\n\nprecision = precision_score(ytest, ypred_class,average='weighted')\nprint('Precision -  %f' % precision)\n\nrecall = recall_score(ytest,ypred_class,average='weighted')\nprint('Recall -  %f' % recall)\n\nf1 = f1_score(ytest,ypred_class,average='weighted')\nprint('F1 score -  %f' % f1)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:10:54.386850Z","iopub.execute_input":"2022-03-16T17:10:54.387106Z","iopub.status.idle":"2022-03-16T17:10:54.406798Z","shell.execute_reply.started":"2022-03-16T17:10:54.387078Z","shell.execute_reply":"2022-03-16T17:10:54.405148Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}